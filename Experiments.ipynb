{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# GoLLIE Experiment Runner (Single-Test Version)\n",
        "\n",
        "This notebook is configured for a **quick test run** (1 module, 1 sentence) to verify the Colab environment."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Project Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "import logging\n",
        "\n",
        "if not os.path.exists(\"GoLLIE\"): !git clone https://github.com/hitz-zentroa/GoLLIE.git\n",
        "if os.path.exists(\"requirements.txt\"): %pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def download_few_nerd():\n",
        "    if os.path.isdir(\"few-nerd_test\"): return\n",
        "    from datasets import load_dataset\n",
        "    ds = load_dataset(\"DFKI-SLT/few-nerd\", name='supervised', split='test')\n",
        "    ds.save_to_disk(\"few-nerd_test\")\n",
        "download_few_nerd()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os, sys, json, re, inspect, logging, black\n",
        "from datetime import datetime\n",
        "from typing import Dict, List, Type, Any\n",
        "from datasets import load_from_disk\n",
        "from jinja2 import Template\n",
        "\n",
        "PROJECT_ROOT = os.getcwd()\n",
        "if PROJECT_ROOT not in sys.path: sys.path.insert(0, PROJECT_ROOT)\n",
        "GOLLIE_PATH = os.path.join(PROJECT_ROOT, \"GoLLIE\")\n",
        "if GOLLIE_PATH not in sys.path: sys.path.append(GOLLIE_PATH)\n",
        "\n",
        "from src.model.load_model import load_model\n",
        "from src.tasks.utils_typing import Entity, AnnotationList\n",
        "from src.tasks.utils_scorer import SpanScorer\n",
        "from annotation_guidelines import guidelines_coarse_gollie\n",
        "\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "\n",
        "MODEL_LOAD_PARAMS = {\n",
        "    \"inference\": True, \"model_weights_name_or_path\": \"HiTZ/GoLLIE-7B\",\n",
        "    \"quantization\": None, \"use_lora\": False, \"force_auto_device_map\": True,\n",
        "    \"use_flash_attention\": True, \"torch_dtype\": \"bfloat16\"\n",
        "}\n",
        "\n",
        "def label_to_classname(label):\n",
        "    if label == \"O\": return None\n",
        "    return \"\".join(p.capitalize() for p in re.split(r'[-/]', label))\n",
        "\n",
        "def run_quick_test():\n",
        "    os.makedirs(\"GOLLIE-results\", exist_ok=True)\n",
        "    ds = load_from_disk(\"./few-nerd_test\")\n",
        "    model, tokenizer = load_model(**MODEL_LOAD_PARAMS)\n",
        "    \n",
        "    with open(os.path.join(GOLLIE_PATH, \"templates/prompt.txt\"), \"rt\") as f:\n",
        "        template = Template(f.read())\n",
        "\n",
        "    module = guidelines_coarse_gollie\n",
        "    sentence = ds[0]\n",
        "    text = \" \".join(sentence[\"tokens\"])\n",
        "    \n",
        "    gold = []\n",
        "    names = ds.features[\"ner_tags\"].feature.names\n",
        "    for token, tag_id in zip(sentence[\"tokens\"], sentence[\"ner_tags\"]):\n",
        "        class_name = label_to_classname(names[tag_id])\n",
        "        if class_name:\n",
        "            cls = getattr(module, class_name, None)\n",
        "            if cls: gold.append(cls(span=token))\n",
        "\n",
        "    prompt = template.render(\n",
        "        guidelines=[inspect.getsource(d) for d in module.ENTITY_DEFINITIONS],\n",
        "        text=text, annotations=gold, gold=gold\n",
        "    )\n",
        "    try: prompt = black.format_str(prompt, mode=black.Mode())\n",
        "    except: pass\n",
        "    \n",
        "    prompt = prompt.split(\"result =\")[0] + \"result =\"\n",
        "    inputs = {k: v[:, :-1].to(model.device) for k, v in tokenizer(prompt, return_tensors=\"pt\").items()}\n",
        "    out = model.generate(**inputs, max_new_tokens=128, do_sample=False)\n",
        "    res = tokenizer.decode(out[0], skip_special_tokens=True).split(\"result =\")[-1]\n",
        "    \n",
        "    print(f\"--- TEST RESULT ---\\nText: {text}\\nGold: {gold}\\nPred: {res}\")\n",
        "run_quick_test()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}